- [12. 로드 밸런서](#12--)
	- [12.1 부하 분산이란?](#121--)
	- [12.2 부하 분산 방법](#122---)
	- [12.3 헬스 체크](#123--)
		- [12.3.1 헬스 체크 방식](#1231---)
			- [12.3.1.1 ICMP](#12311-icmp)
			- [12.3.1.2 TCP 서비스 포트](#12312-tcp--)
			- [12.3.1.3 TCP 서비스 포트 : Half Open](#12313-tcp----half-open)
			- [12.3.1.4 HTTP 상태 코드](#12314-http--)
			- [12.3.1.5 콘텐츠 확인(문자열 확인)](#12315---)
		- [12.3.2 헬스 체크 주기와 타이머](#1232----)
	- [12.4 부하 분산 알고리즘](#124---)
		- [12.4.1 라운드 로빈](#1241--)
		- [12.4.2 최소 접속 방식](#1242---)
		- [12.4.3 해시](#1243-)
	- [12.5 로드 밸런서 구성 방식](#125----)
		- [12.5.1 원암 구성](#1251--)
		- [12.5.2 인라인 구성](#1252--)
	- [12.6 로드 밸런서 동작 모드](#126----)
		- [12.6.1 트랜스패런트 모드](#1261--)
		- [12.6.2 라우티드 모드](#1262--)
		- [12.6.3 DSR 모드](#1263-dsr-)
			- [12.6.3.1 리눅스 서버에서 루프백 인터페이스 설정](#12631-----)
			- [12.6.3.2 윈도우 서버에서 루프백 인터페이스 설정](#12632-----)
	- [12.7 로드 밸런서 유의사항](#127---)
		- [12.7.1 원암 구성의 동일 네트워크 사용 시`](#1271------)
			- [12.7.1.1 게이트웨이를 로드 밸런서로 설정](#12711----)
			- [12.7.1.2 Source NAT 사용](#12712-source-nat-)
			- [12.7.1.3 DSR 모드](#12713-dsr-)
		- [12.7.2 동일 네트워크 내에서 서비스 IP(VIP) 호출](#1272-----ipvip-)
	- [12.8 HAProxy를 사용한 로드 밸런서 설정](#128-haproxy----)
		- [12.8.1 HAProxy 설치](#1281-haproxy-)
		- [12.8.2 HAProxy 설정](#1282-haproxy-)
		- [12.8.3 HAProxy 동작 및 모니터링](#1283-haproxy---)



# 12. 로드 밸런서


- 안정성, 가용성을 위해 서비스 자체적으로 HA 클러스터를 구성하기도 하지만
- 로드 밸런서 쓰면 복잡한 고려 없이 이중화 구현 가능


- 다양한 구성 방식, 동작 모드 있고
- 각 방식과 모드에 따라 서비스 흐름이나 패킷 내용이 달라짐


## 12.1 부하 분산이란?
- 서비스 규모 거치면 물리나 가상 서버 한 대로는 모든 서비스 수용 불가
- 또한 서버 한 대로 서비스하면 문제 생겼을 때 정상적인 서비스 제공 불가능
- 가용성을 높이기 위해서는 보통 두 대 이상의 서버로 구성


![](files/Pasted%20image%2020250516193422.png)


- 각 서버의 IP 주소가 다르므로 사용자는 어떤 IP로 요청할 건지 결정해야 함
- 사용자마다 IP가 다르면 장애 범위는 줄일 수 있지만 여전히 부분적으로 장애는 발생


- 이를 해결하기 위해 L4나 L7 스위치라는 로드밸런서 사용
-  동일한 서비스를 하는 다수의 서버가 등록되고, 사용자로부터 서비스 요청이 오면 LB가 받아 여러 서버에 요청을 분산시켜 부하를 분산
- 대규모 서비스에는 LB는 필수


![](files/Pasted%20image%2020250516193540.png)


- LB는 서비스를 위한 하나의 가상 IP(VIP)를 제공하고, 사용자는 각 서버의 개별 IP 주소가 아닌 동일한 가상 IP를 통해 각 서버로 접근
- 이 외에도 로드 밸런서는 각 서버의 서비스 상태를 체크해 서비스가 가능한 서버로만 사용자 요청을 분산 -> 서버에 장애가 발생해도 다른 서버에 요청을 보내 정상 서비스 가능


- FWLB
	- 방화벽을 액티브-액티브로 구성하기 위해 LB를 쓰기도 함
	- 서버 부하 분산을 SLB(Server Load Balancing)
	- 방화벽 부하 분산을 FWLB(FIreWall Load Balancing)


![](files/Pasted%20image%2020250516193751.png)


- 방화벽은 세션을 사용
- 단순히 방화벽을 이중화하면 비대칭 동작으로 문제가 생길 수 있음
- FWLB가 세션을 인식하고 일정한 규칙을 이용해 방화벽 세션을 분산 (해시 알고리즘)
- 한 번 방화벽을 지나갔던 세션이 다시 같은 방화벽을 지나가도록 트래픽을 분산


- FWLB 사용해도 방화벽에 장애가 발생하는 경우를 대비해 방화벽에서 설정이 필요
- 방화벽끼리 세션 테이블 동기화하거나, 방화벽에서 첫 번째 패킷이 SYNC가 아니더라도 허용하는 등


## 12.2 부하 분산 방법
- LACP는 두 개 이상의 인터페이스를 하나의 논리 인터페이스로 묶어 회선의 부하 분산
- LACP는 다수의 물리 인터페이스를 하나의 논리 인터페이스로 구성하기 위해 LACP를 위한 가상의 MAC 주소 생성
- LB도 이와 유사하게 가상 IP 가진다
- 이는 VIP라고도 하고, 서비스 IP 주소라고도 한다.


- 가상 IP가 있으면 실제 IP도 있다
- 서버의 실제 IP를 Real IP라고 부른다
- 가상 IP에 실제 서버 IP가 바인딩된다
- RIP라고도 부름


- LB는 리얼 IP와 VIP가 있고, VIP에는 RIP가 바인딩 되어있으며 사용자가 VIP로 서비스 요청하면 해당 VIP에 연결된 리얼 IP로 해당 요청을 전달.


![](files/Pasted%20image%2020250516195524.png)


- LB로 부하 분산 그룹 만들 때는 IP 주소뿐만 아니라 4계층 정보인 서비스 포트까지 지정해서 만든다
- 그래서 로드 밸런서를 L4 스위치라고 함
- 7계층 정보도 처리하는 경우도 있는데, 이때는 L7 스위치라고 함
- 보통 LB는 L4 스위치라고 부름


- 위 사진에서는 HTTP, HTTPS 모두 동일한 VIP를 썼지만 서로 다른 VIP로 구성하는 것도 가능
- 또한 LB의 VIP에 설정된 서비스 포트와 실제 서버의 서비스 포트는 반드시 같을 필요도 없음


![](files/Pasted%20image%2020250516195718.png)


## 12.3 헬스 체크
- 서버에 장애 발생하면 어떻게 될까
- LB가 거기로 트래픽 흘리면?
- LB는 서버의 서비스를 주기적으로 헬스 체크해 정상 서비스로만 부하를 보내므로 문제가 되지 않는다


### 12.3.1 헬스 체크 방식
- 다양한 방법 있음


#### 12.3.1.1 ICMP
![](files/Pasted%20image%2020250516200546.png)
- ICMP(ping)으로 헬스 체크 수행
- 단순히 서버 살아있나만 확인하므로 잘 쓰지 않음


#### 12.3.1.2 TCP 서비스 포트
![](files/Pasted%20image%2020250516200630.png)
- 서버의 서비스 포트 확인
- SYN 보내고 리얼 IP를 가진 서버로부터 SYN, ACK 받으면 다시 ACK 응답하고 FIN 보내 헬스 체크 종료
- 서비스 포트를 이용해 헬스 체크할 때는 실제 서비스 포트가 아닌 다른 서비스 포트로도 가능


#### 12.3.1.3 TCP 서비스 포트 : Half Open
![](files/Pasted%20image%2020250516200754.png)
- 일반적으로 TCP 서비스 포트 확인할 떄는 SYN/SYN, ACK/ACK까지 정상적인 3-way-handshake 거침
- 헬스 체크로 인한 부하를 줄이거나, 정상적인 방식보다 빨리 헬스 체크 세션 끊기 위해 TCP Half Open 방식을 쓰기도 한다
- 초기의 3-way-handshake처럼 SYN 보내고 SYN, ACK 받지만 이후 ACK 대신 RST 보내서 세션을 끊는다


#### 12.3.1.4 HTTP 상태 코드
![](files/Pasted%20image%2020250516200850.png)
- TCP는 정상이어도 웹 서비스 응답은 아닌 경우도 있다
- HTTP 상태 확인하도록 하면 3-way-handshake 거치고 HTTP 요청해 정상 상태 코드(200) 응답하는지 여부 체크해서 헬스 체크 수행 가능


#### 12.3.1.5 콘텐츠 확인(문자열 확인)
![](files/Pasted%20image%2020250516201028.png)
- 응답받은 내용을 확인해 지정된 콘텐츠가 정상인지 확인하는 방법도 있다
- 보통 특정 웹페이지 호출해 사전에 지정한 문자열이 해당 페이지에 포함되는지 체크
- 이를 사용하면 로드밸런서에서 직접 관리하는 서버의 상태뿐만 아니라 해당 서버의 백엔드의 상태를 해당 웹페이지로 체크할 수 있다


- 단, 문자열을 잘못 체크하면 비정상 응답도 정상으로 판단될 수 있다
- 따라서 정상 코드 값도 중복으로 체크하거나 문자열 자체를 일반적이지 않은 문자열로 지정해야 한다.


![](files/Pasted%20image%2020250516201106.png)


- 참고
	- 3-way vs 4-way 연결 종료(close)
	- 위에서는 4-way-handshake로 연결 종료했지만 3-way-handshake로 연결 종료하기도 한다.


### 12.3.2 헬스 체크 주기와 타이머
- 주요 타이머 값
	- 주기
		- 헬스 체크 패킷 보내는 주기
	- 응답 시간
		- 헬스 체크 패킷을 보내고 응답을 기다리는 시간
		- 해당 시간까지 응답이 오지 않으면 실패로 간주
	- 시도 횟수
		- 헬스 체크 실패 시 최대 시도 횟수
	- 타임아웃
		- 헬스 체크 실패 시 최대 대기 시간
		- 헬스 체크 패킷을 서버로 전송 후 이 시간 내에 성공하지 못하면 해당 서버 다운으로 간주
	- 서비스 다운시의 주기(Dead Interval)
		- 서비스 다운 시 헬스 체크 주기
		- 서비스가 죽은 상태에서 헬스 체크 주기를 별도로 늘릴 때 사용


![](files/Pasted%20image%2020250516201313.png)


- 주기가 3초라면 3초마다 헬스 체크 수행
- 원 모양 사이의 시간이 3초


- 마름모 모양은 서버의 응답을 최대로 기다리는 시간
- 응답 시간으로 설정된 시간 내에 서버 응답이 오지 않으면 LB는 해당 헬스 체크 시도를 실패로 간주
- 주기를 응답 시간보다 크게 설정


- 정상 응답 못 받으면 정해진 시도 횟수만큼 헬스 체크를 다시 시도
- 이후에도 응답을 받지 못하면 다운된 것으로 체크


- 다운까지의 동작을 헬스 체크 주기, 시도 횟수, 응답 시간으로 산정하거나 전체 타임아웃 시간으로 산정
- 헬스 체크가 실패한 첫 번째 시도부터 사전에 정해진 타임아웃까지 헬스 체크가 실패하면 서비스 다운으로 체크


- 서비스 다운되면 더 긴 주기로 헬스 체크를 수행하기도 한다
- 부하를 감소시킬 수 있다는 장점
- 하지만 서비스가 다시 올라오기까지 시간이 늦어진다


## 12.4 부하 분산 알고리즘


| 부하 분산 알고리즘                          | 설명                                                                                   |
|---------------------------------------------|--------------------------------------------------------------------------------------|
| 라운드 로빈 (Round Robin)                   | 현재 구성된 장비에 부하를 순차적으로 분산함. 총 누적 세션 수는 동일하지만 활성화된 세션 수는 달라질 수 있음 |
| 최소 접속 방식 (Least Connection)           | 현재 구성된 장비 중 가장 활성화된 세션 수가 적은 장비로 부하를 분산함                       |
| 가중치 기반 라운드 로빈 (Weighted Round Robin) | 라운드 로빈 방식과 동일하지만 각 장비에 가중치를 두어 가중치가 높은 장비에 부하를 더 많이 분산함. 처리 용량이 다른 서버에 부하를 분산하기 위한 분산 알고리즘 |
| 가중치 기반 최소 접속 방식 (Weighted Least Connection) | 최소 접속 방식과 동일하지만 각 장비에 가중치를 부여해 가중치가 높은 장비에 부하를 더 많이 분산함. 처리 용량이 다른 서버에 부하를 분산하기 위한 분산 알고리즘 |
| 해시 (Hash)                                 | 해시 알고리즘을 이용한 부하 분산                                                       


### 12.4.1 라운드 로빈
![](files/Pasted%20image%2020250517150609.png)


- 순차적으로 트래픽 분산
- 모든 장비의 총 누적 세션 수는 같아짐


### 12.4.2 최소 접속 방식
![](files/Pasted%20image%2020250517150629.png)


- Least Connection은 세션 부하를 확인해 그것에 맞게 부하를 분산
- LB에는 세션 테이블이 있어 현재 세션 수를 알 수 있음
- 현재 세션이 가장 적게 연결된 장비로 요청 보내기
- 활성화 세션 수가 비슷해짐


### 12.4.3 해시
![](files/Pasted%20image%2020250517150636.png)


- 서버 부하 고려하지 않고 클라이언트가 같은 서버에 지속적으로 접속하도록 하는 방식
- 해시 알고리즘으로 장비 결정


- 보통 출발지 IP, 목적지 IP, 출발지 포트, 목적지 포트 사용



- 라운드 로빈, 최소 접속 방식은 비교적 비슷한 비율로 부하 분산 가능
- 그러나 세션을 유지해야 하는 서비스에는 사용 불가


- 반대로 해시 방식은 세션 유지해야 하는 서비스에 적합
- 하지만 결과값이 특정한 값으로 치우치면 부하 분산이 제대로 이루어지지 않을 수 있음


- 묶어서 쓰기도 함
- 라운드 로빈이나 최소 접속 방식을 사용하면서 Sticky 옵션을 줘서 한 번 접속한 커넥션을 지속적으로 유지
- 단, 세션 테이블에는 타임아웃이 있어 타임아웃 이후에는 분산되는 장비가 달라짐
- 따라서 애플리케이션 세션 유지 시간이나 일반 사용자들의 애플리케이션 행동 패턴을 충분히 감안해야 함


## 12.5 로드 밸런서 구성 방식
![](files/Pasted%20image%2020250517150646.png)


- 원암 구성은 LB가 중간 스위치 옆에 연결
- 인라인 구성은 서버로 가는 경로 상에 LB가 연결되는 구성
- 원암이라고 해서 LB와 스위치 간 연결된 인터페이스가 한 개라는 건 아님


- 실질적으로 원암과 인라인 구분은 서버로 가는 트래픽이 모두 LB를 경유하는지, 경유하지 않아도 되는지로 구분
- 원암 구성은 부하 분산을 수행하는 트래픽만 LB 경유
- 인라인 구성은 모든 트래픽이 LB를 경유


### 12.5.1 원암 구성
![](files/Pasted%20image%2020250517150715.png)


- 원암 구성은 LB가 스위치 옆에 있는 형태


![](files/Pasted%20image%2020250517150755.png)


- 물리 인터페이스가 하나라는 뜻은 아니고, LACP처럼 다수의 인터페이스로 스위치가 연결된 경우도 원암 구성이라고 한다
- 또한 두 개 이상의 인터페이스를 LACP가 아닌 서로 다른 네트워크로 구성해도 원암 구성이 될 수 있다(투암 구성이라고도 부름)


![](files/Pasted%20image%2020250517150807.png)


- 서버로 들어가거나 나가는 트래픽이 LB를 경유하지 않을 수도 있다
- 부하 분산을 이용하는 트래픽인지에 따라 다르다
- 부하 분산을 이용한다면 부하 분산에 사용되는 서비스 IP를 LB가 가지고 있어 서버로 유입되는 트래픽은 먼저 LB를 거친다
- LB는 각 실제 서버로 트래픽을 분산하고 서버 응답은 다시 LB를 거쳐 사용자에게 응답


- 원암 구조에서 서버의 응답 트래픽이 LB를 다시 거치려면 LB를 거칠 때 서비스 IP에 대한 실제 서버로 NAT은 물론 서비스를 호출한 사용자 IP가 아니라 로드 밸런서가 가진 IP로 Source NAT도 함께 이루어져야 한다.
- Source NAT을 하지 않으려면 DSR(Direct Server Return) 사용하면 된다.



![](files/Pasted%20image%2020250517150813.png)


- 부하 분산을 이용하지 않는다면 굳이 LB를 거치지 않아도 서버와 통신 가능
- 따라서 LB 부하를 줄일 수 있음
- 스위치 <-> LB 대역폭 최소화할 수 있고, 대역폭이 부족할 때는 이 구간만 증설하면 되므로 인라인 방식보다는 상대적으로 확장에 유리


- 원암 구성은 LB 부하 감소는 물론 장애 영향도를 줄이기 위해서도 사용됨
- LB에 장애가 생겨도 LB 거치지 않는 트래픽 흐름에는 문제가 없음
- 원암 구성은 LB 통과해야 하는 트래픽과 통과하지 않아도 되는 트래픽이 섞인 경우 많이 사용


- 원암 구성 시 LB를 경유하는 트래픽이 감소해 LB가 처리해야 하는 용량이 줄어든다
- 하지만 LB와 스위치 간 연결된 인터페이스는 인바운드, 아웃바운드 트래픽 모두 수용해야 하므로 이를 바탕으로 산정 필요


### 12.5.2 인라인 구성
![](files/Pasted%20image%2020250517150820.png)


- 트래픽이 흐르는 경로에 LB가 있어 LB 사용 여부와 무관하게 LB를 통과


![](files/Pasted%20image%2020250517150825.png)


- 모든 트래픽 경로가 동일하므로 구성이 직관적, 이해하기 쉬움
- 대신 모든 트래픽이 LB를 경유해 LB 부하가 올라감
- 특히 L3 역할하는 스위치와 달리 LB는 4계층 이상 데이터 처리하므로 처리 가능한 용량이 L3보다 적다
	- 성능 높이면 가격도 비싸짐
- LB에서 처리하지 않는 트래픽이 LB를 거쳐도 그 부하가 크지는 않다
- 인라인으로 LB 선정할 때 LB 성능과 패킷 스루픗 성능을 구별해 디자인



- 이 외에도 인라인 구성에서도 원암 구성처럼 응답 트래픽이 LB를 거치지 못하는 경우가 발생할 수 있다
- 이 또한 원암 구성과 동일하게 조치 가능. 아래에서 살펴보자



- 물리적 원암, 논리적 인라인
	- 물리적으로 원암 구성이어도 실제로는 인라인 구성인 경우가 있다
	- LB와 연결된 스위치 상에서 VRF와 같은 가상화를 사용해 논리적으로 장비를 분리하는 경우
	- VRF까지 안 가도 VLAN만으로도 가능
	- 이런 경우 물리적 구성이 아니라 장비의 논리적 구성도로 이해하면 일반적인 인라인 구성이 된다
	- 물리적 구성만 보고 구분하면 안 된다.


## 12.6 로드 밸런서 동작 모드
- 트랜스패런트(Transparent: TP) 또는 브릿지(Bridge)
• 라우티드(Routed)
• DSR(Direct Server Return)


### 12.6.1 트랜스패런트 모드
- LB가 OSI 2계층 스위치처럼 동작
- 즉, VIP 주소와 실제 서버가 동일한 네트워크 사용
- 기존 네트워크 대역을 그대로 사용하므로 LB 도입으로 인한 IP 네트워크 재설계를 고려하지 않아도 됨
- 네트워크에 L2 스위치 추가하는 것처럼 기존 망의 트래픽 흐름 영향 없이 LB 구성 가능


- 트래픽이 LB를 지나더라도 부하 분산 서비스를 받는 트래픽만 4계층 이상의 기능을 수행
- 따라서 기존 L2 스위치와 동일한 스위칭 기능만 수행 -> L2 구조라고도 부름


![](files/Pasted%20image%2020250517193622.png)


- 트랜스패런트 모드는 원암과 인라인 모드 사용 가능
- 단, 원암 구성에서는 응답 트래픽 경로가 문제가 될 수 있으므로 Source NAT 필요
- 여기서는 인라인만 봐보자


![](files/Pasted%20image%2020250517193651.png)


- LB로 들어온 패킷은 목적지 IP 주소를 VIP에 바인딩된 실제 서버 IP로 변경
- 목적지 MAC 주소도 실제 서버 MAC 주소가 됨
- LB, 목적지 서버 모두 동일한 네트워크 대역이므로 L3 장비 지날 때처럼 출발지 MAC 주소가 바뀌지는 않음


- LB에서 서비스를 위한 VIP 주소가 실제 서비스 IP 주소로 바뀌므로 Destination NAT


![](files/Pasted%20image%2020250517193846.png)


- 출발지 IP 주소가 실제 서버 IP 주소 -> VIP 주소로 바뀜
- 단, 목적지 MAC 주소는 바뀔 필요가 없음
- 서버에서 응답할 때 이미 목적지 MAC 주소가 이미 게이트웨이의 MAC 주소를 가지고 있음


- 인라인 구성에서는 게이트웨이 외부 사용자로부터 받은 서비스 요청을 처리하는 데는 문제가 없음
- 동일 네트워크에서 서비스를 호출할 때는 서비스 응답이 LB를 거치지 않을 수도 있음
- 원암 구성에서도 응답이 LB를 거치지 않을 수 있고, 이때 서비스에 문제가 생길 수 있음
	- 응답 패킷이 LB를 거쳐 다시 역변환이 되어야 정상적인 부하 분산이 가능



- 트랜스패런트 모드를 구현할 때는 내부적으로 프록시 ARP를 이용하기도 한다
	- 이 경우에는 MAC 주소를 변경한다
	- 최근에는 대부분 순수 트랜스패런트 모드를 사용


### 12.6.2 라우티드 모드
- LB가 라우팅 역할 수행
- LB를 기준으로 사용자 방향과 서버 방향이 서로 다른 네트워크로 분리된 구성
- LB는 사용자 방향과 서버 방향의 네트워크를 라우팅으로 연결
- 인라인, 원암 구성 둘 다 가능


![](files/Pasted%20image%2020250517194319.png)


- 보안 강화 목적으로 서버 쪽 네트워크를 사설로 구성해 서버 직접 접속을 막는 용도로 사용되기도 함


![](files/Pasted%20image%2020250517194631.png)


- 사용자는 VIP로 요청
- LB로 들어온 패킷은 목적지 IP를 VIP -> SIP로 변경
- 라우팅을 수행하면서 LB를 통과하므로 출발지, 목적지 MAC 주소도 A -> D, B -> C로 변경된다.
- 라우팅 테이블을 확인해 실제 서버로 전성됨
- VIP -> SIP로 바꾸므로 Destination NAT 수행됨


![](files/Pasted%20image%2020250517194726.png)


- 서버가 응답하면 출발지는 SIP, 목적지는 실제 사용자의 IP
- 단, 목적지 IP는 외부 네트워크이므로 목적지 MAC은 외부로 나가는 관문인 LB의 MAC 주소가 됨
- LB로 들어온 패킷은 출발지 IP를 SIP -> VIP로 변경
- 출발지, 목저지 MAC 주소도 변경 후 응답


> 인라인 모드의 라우티드 구성에서 LB가 게이트웨이 역할을 할 수도 있고 LB와 서버 사이에 또 다른 L3 장비가 있는 경우 L3 장비에서 게이트웨이 역할을 할 수도 있다.


### 12.6.3 DSR 모드
- Direct Server Return
- 사용자의 요청이 서버를 통해 유입된 후 다시 LB를 통하지 않고 서버가 사용자에게 응답하는 방식
- LB에는 응답 트래픽이 유입되지 않아 사용자가 요청하는 패킷에 대해서만 관여
- DSR 모드로 응답할 때, LB를 경유하지 않아 원암으로 구성


- L2 DSR, L3 DSR 구분
- L2 DSR은 실제 서버의 네트워크를 LB가 가진 경우
- L3 DSR은 실제 서버의 네트워크 대역을 LB가 가지지 않은 경우
- 즉, LB -> 실제 서버까지의 통신이 L2냐 L3냐


![](files/Pasted%20image%2020250517195420.png)


- DSR은 LB 전체 트래픽이 감소해 LB 부하가 감소
- 특히, 일반적인 서비스 트래픽은 응답이 요청보다 크므로 LB 트래픽 부하 감소에 효과적
	- 스트리밍 서비스 같은 경우도 마찬가지


- 단, LB를 경유하지 않아 문제가 발생했을 때 문제 확인이 어렵다
- L2 DSR, L3 DSR은 LB 설정 외에 서버에서도 추가 설정이 필요


![](files/Pasted%20image%2020250517200043.png)


- 왜 추가 설정이 필요할까?
	- 사용자는 VIP로 서비스 요청
	- LB로 들어온 서비스 요청 패킷은 트랜스패런트나 라우티드 방식이면 목적지 IP 주소가 LB를 거치면서 실제 서버의 IP로 DNAT
	- 하지만 DSR 모드에서는 LB를 거치지 않고 응답해야 하므로 로드 밸런서를 통한 출발지 IP를 변경하는 SNAT을 수행
	- SNAT이 없으므로 사용자 입장에서는 VIP로 요청 보냈는데 응답은 SIP로부터 옴
	- 즉, 사용자는 이를 비정상 패킷으로 간주


- 따라서 DSR 모드인 경우 LB는 서비스를 요청할 때 목적지 IP는 실제 서버 IP로 변경하지 않고 VIP 그대로 유지
- 목적지 MAC 주소만 실제 서버 MAC 주소로 변경


- 서버에서는 해당 패킷을 수신하면 목적지 IP 주소가 서버 주소와 맞지 않으면 폐기된다
- 따라서 루프백 인터페이스를 생성해 VIP 주소를 할당
- 또한 루프백에 설정된 IP 주소더라도 패킷을 수신할 수 있도록 설정
- 마지막으로 VIP는 로드밸런서 IP와 중복되므로 ARP에 의해 중복된 IP에 대한 MAC이 갱신되지 않도록 서버에 설정된 VIP에 대해서는 ARP 광고가 되지 않도록 설정


> 루프백 인터페이스는 자기 자신과 통신하기 위한 가상 인터페이스
> 대표적으로 `127.0.0.1`이 있음
> VIP를 루프백 인터페이스 IP 주소로 설정하면 외부에서 오는 VIP 요청을 자기 자신에 대한 요청으로 인식하고 처리 가능



![](files/로드%20밸런서.png)


- 사용자는 VIP로 서비스 요청
- LB는 목적지 IP를 VIP로 두고, 목적지 MAC 주소만 실제 MAC 주소로 변경
- 실제 서버에서는 루프백 인터페이스에 VIP와 동일한 IP 설정되어 있고, 목적지 IP가 루프백 IP와 동일한 경우에도 패킷을 수신


![](files/Pasted%20image%2020250517200449.png)


- DSR 응답은 LB가 개입하지 않아 LB를 사용하지 않는 일반 패킷과 유사하게 전달
- 단, VIP를 출발지 주소로 설정해서 패킷 전송


#### 12.6.3.1 리눅스 서버에서 루프백 인터페이스 설정
- CentOS
```
DEVICE=lo:0
IPADDR=서비스용 가상 IP(VIP)
NETMASK=255.255.255.255
ONBOOT=yes
NAME=lo0
```
- 우분투
```
auto lo lo:0
iface lo inet loopback
iface lo:0 inet static
        address 서비스 가상 IP(VIP)
        netmask 255.255.255.255
```


- 이후 해당 IP가 LB IP와 같으므로 ARP를 통한 테이블이 갱신되지 않도록 해당 서버의 리눅스 커널 파라미터 수정
- 즉, 해당 인터페이스가 GARP(Gratuitous ARP)를 보내거나 ARP 응답하지 않도록 설정


```
# /etc/sysctl.conf


net.ipv4.conf.lo.arp_ignore=1
net.ipv4.conf.lo.arp_announce=2
net.ipv4.conf.all.arp_ignore=1
net.ipv4.conf.all.arp_announce=2
```


- 이후 네트워크 재시작


```sh
systemctl network restart 또는 service network restart     # RHEL(CentOS)
service networking restart 또는 service networking restart # 데비안(우분투)
```


#### 12.6.3.2 윈도우 서버에서 루프백 인터페이스 설정


## 12.7 로드 밸런서 유의사항


### 12.7.1 원암 구성의 동일 네트워크 사용 시`
![](files/Pasted%20image%2020250517201058.png)


- 사용자가 VIP로 요청하면 LB에서는 실제 서버의 IP 주소로 DNAT 한 후 서버로 전달
- 서버는 다시 사용자에게 응답할 때 게이트웨이 장비인 L3 스위치를 통해 응답
- 인라인은 항상 LB를 통과하지만 원암 구성에서는 LB를 거치지 않고 사용자에게 바로 응답
- 따라서 사용자 입장에서는 VIP로 요청했지만 SIP로 응답을 받음


- 즉, LB를 거치면서 변경된 IP가 재응답할 때 LB를 경유하면서 다시 원래 IP로 바뀌어야 하는데 원암 구조에서는 응답 트래픽이 LB를 경유하지 않아서 발생


- 그러면 어떻게 해결할 수 있을까
#### 12.7.1.1 게이트웨이를 로드 밸런서로 설정
![](files/Pasted%20image%2020250517201003.png)


- 동일 네트워크가 아닌 목적지로 가려면 게이트웨이 통과해야 함
- 즉, LB를 통해 부하 분산이 이루어지는 실제 서버에 대해서는 게이트웨이를 LB로 설정하면 로컬 네트워크가 아닌 외부 사용자의 호출에 대한 응답이 항상 LB를 경유하므로 문제 해결 가능


- 단, 이는 물리적으로는 원암 구조이지만 실제 트래픽 흐름은 LB를 게이트웨이로 사용하므로 원암 구조에서 얻을 수 있는 LB 부하 감소 효과가 줄어든다
- 물론, 부하 분산을 사용하지 않는 서버는 기존과 동일하게 게이트웨이를 L3 스위치로 설정하면 LB를 경유하지 않아 LB 부하 감소 효과를 가져올 수 있다


#### 12.7.1.2 Source NAT 사용
![](files/Pasted%20image%2020250517201009.png)


- 또 다른 방법은 SNAT 적용하는 것
- 사용자의 서비스 요청에 대해 LB가 실제 서버로 갈 때 DNAT만 하지 않고 출발지 IP 주소를 LB IP 주소로 변경하는 SNAT 수행
- 그러면 사용자는 LB가 서비스 요청한 것처럼 보이므로 응답을 항상 LB로 보내 
- 즉, 호출할 때, 응답할 때 모두 SNAT, DNAT 수행


- 단, 이 방식은 애플리케이션 입장에서 보면 서비스를 호출한 IP가 동일한 IP로 보이므로 사용자 구분이 어려움
- 따라서 HTTP 헤더의 X-Forwarded-For(XFF) 등을 사용하기도 함


#### 12.7.1.3 DSR 모드
![](files/Pasted%20image%2020250517203814.png)


- 원암 구조의 동일 네트워크에서 DSR 모드 사용할 수 있다


### 12.7.2 동일 네트워크 내에서 서비스 IP(VIP) 호출
![](files/Pasted%20image%2020250517201038.png)


- 원암이든, 인라인이든 같은 네트워크면 응답을 LB를 거치지 않고 바로 보내버릴 수도 있다
- 요청한 IP 주소가 아닌 다른 IP 주소로 응답이 오므로 해당 패킷은 폐기됨


- 이를 해결하는 방법도 위와 거의 같다
	- 출발지 IP 주소를 LB IP로 바꾸는 SNAT을 하거나
	- DSR 모드를 사용해 LB를 거치지 않고 응답시키거나
	- 혹은 서버를 LB에 직접 연결해 어떤 서비스 요청에 대한 응답이든 물리적으로 LB를 거치게 하거나
		- 단 이는 LB 포트 수 제한이 있어 확장에 제한적
		- 포트 수 많아지면 엄청 비싸짐 -> 권장 X


- 이 외에도 다양한 문제가 발생할 수 있음
- SNAT 사용하면 서비스 요청이 매우 많을 때 SNAT 할 수 있는 서비스 포트 범위가 제한적이라 SNAT IP 주소를 범위로 지정해야 할 수도 있다.


- 서비스 흐름, 요건에 따라 최적화된 LB 구성이나 동작 모드가 달라짐


## 12.8 HAProxy를 사용한 로드 밸런서 설정
- 기존 하드웨어 LB를 일반 서버에서 직접 수행하게 해주는 오픈소스 소프트웨어 LB
- NFV(Network Function Virtualization)이라고 볼 수 있음


- 간단한 설정만으로 사용할 수 있어 하드웨어 LB에 비해 빠르게 LB 서비스 제공 가능
- 소프트웨어 형태이므로 가상화나 클라우드 환경에서 LB로 사용하기 적합
- 쿠버네티스 Ingress Controller 역할도 가능


- 커뮤니티, 엔터프라이즈 버전 있음
- Hardware Appliance 형태의 ALOHA 로드 밸런서도 있음


- 기능 대부분은 이미 제공하고 있고
- 새로운 기능 계속 추가되고 있음
- 대부분의 환경의 상용 하드웨어 로드 밸런서 대체 가능



### 12.8.1 HAProxy 설치



### 12.8.2 HAProxy 설정


### 12.8.3 HAProxy 동작 및 모니터링


웹 Ui도 있다~
![](files/Pasted%20image%2020250521194356.png)


